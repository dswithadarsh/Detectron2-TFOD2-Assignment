{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Detectron2 & TFOD2 | Assignment"
      ],
      "metadata": {
        "id": "lqffssimUyeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Detectron2 and how does it differ from previous object detection frameworks?"
      ],
      "metadata": {
        "id": "mEYDU56rU3Jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "6OdNtrXjU8Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detectron2 is an open-source object detection and segmentation framework developed by Facebook AI Research (FAIR). It is built on PyTorch and provides state-of-the-art implementations of modern computer vision algorithms.\n",
        "\n",
        "Detectron2 supports:\n",
        "\n",
        "  * Object Detection\n",
        "\n",
        "  * Instance Segmentation\n",
        "\n",
        "  * Semantic Segmentation\n",
        "\n",
        "  * Keypoint Detection\n",
        "\n",
        "How Detectron2 differs from previous frameworks:\n",
        "\n",
        "1. Modular Design:\n",
        "Detectron2 uses a highly modular architecture, making it easier to customize models, datasets, and training pipelines.\n",
        "\n",
        "2. PyTorch-based:\n",
        "Unlike older frameworks such as Detectron (Caffe2-based), Detectron2 is fully built on PyTorch, which improves flexibility and debugging.\n",
        "\n",
        "3. State-of-the-art Models:\n",
        "It includes advanced models like Faster R-CNN, Mask R-CNN, RetinaNet, and Cascade R-CNN.\n",
        "\n",
        "4. Better Performance:\n",
        "Optimized training loops and improved evaluation metrics result in higher accuracy and faster convergence.\n",
        "\n",
        "5. COCO Standard Support:\n",
        "Native support for COCO-format datasets and metrics."
      ],
      "metadata": {
        "id": "Mw2Q4HO-U_CQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the process and importance of data annotation when working with Detectron2."
      ],
      "metadata": {
        "id": "AldXqOLKVap7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "oHGSvcgDVhXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data annotation is the process of labeling images with bounding boxes, segmentation masks, or keypoints so that Detectron2 can learn object patterns.\n",
        "\n",
        "Process of Data Annotation:\n",
        "\n",
        "1. Collect raw images\n",
        "\n",
        "2. Use annotation tools (LabelImg, CVAT, Roboflow, etc.)\n",
        "\n",
        "3. Draw bounding boxes or masks\n",
        "\n",
        "4. Assign class labels\n",
        "\n",
        "5. Export annotations in COCO format\n",
        "\n",
        "Importance of Data Annotation:\n",
        "\n",
        "* Detectron2 requires structured labeled data\n",
        "\n",
        "* High-quality annotations improve model accuracy\n",
        "\n",
        "* Poor annotation leads to incorrect predictions\n",
        "\n",
        "* Enables supervised learning"
      ],
      "metadata": {
        "id": "MrhwUSxaVjrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Describe the steps involved in training a custom object detection model using Detectron2."
      ],
      "metadata": {
        "id": "UxTaCesKV0oV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "df3EvaNHV3th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to train a custom model using Detectron2:\n",
        "\n",
        "1. Install Detectron2\n",
        "\n",
        "2. Prepare dataset in COCO format\n",
        "\n",
        "3. Register dataset using DatasetCatalog\n",
        "\n",
        "4. Select a pretrained model from Model Zoo\n",
        "\n",
        "5. Modify configuration file\n",
        "\n",
        "6. Train the model\n",
        "\n",
        "7. Evaluate performance\n",
        "\n",
        "8. Save trained weights"
      ],
      "metadata": {
        "id": "DdNHwq_EV56K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are evaluation curves in Detectron2, and how are metrics like mAP and IoU interpreted?"
      ],
      "metadata": {
        "id": "qeFUxcE7WOsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "uMMlCRUrWRRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation curves visualize how well a model performs.\n",
        "\n",
        "IoU (Intersection over Union):\n",
        "\n",
        "IoU=\n",
        "Area of Union\n",
        "/\n",
        "Area of Overlap\n",
        "\t​\n",
        "\n",
        "\n",
        "* Measures overlap between predicted and ground truth boxes\n",
        "\n",
        "* IoU ≥ 0.5 is usually considered correct\n",
        "\n",
        "mAP (mean Average Precision):\n",
        "\n",
        "* Average precision across multiple IoU thresholds\n",
        "\n",
        "* COCO uses IoU from 0.5 to 0.95\n",
        "\n",
        "* Higher mAP means better detection accuracy"
      ],
      "metadata": {
        "id": "Vrv37f6iWTcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compare Detectron2 and TFOD2 in terms of features, performance, and ease of use."
      ],
      "metadata": {
        "id": "spPCe0-DXQON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "Ysyom3iPXXR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature       | Detectron2               | TFOD2             |\n",
        "| ------------- | ------------------------ | ----------------- |\n",
        "| Framework     | PyTorch                  | TensorFlow        |\n",
        "| Models        | Faster R-CNN, Mask R-CNN | SSD, EfficientDet |\n",
        "| Ease of Use   | Moderate                 | Beginner-friendly |\n",
        "| Performance   | High accuracy            | Faster inference  |\n",
        "| Customization | Very flexible            | Limited           |\n"
      ],
      "metadata": {
        "id": "-PgbvEEYXYka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write Python code to install Detectron2 and verify the installation."
      ],
      "metadata": {
        "id": "b_gI8yqJXa9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "7kXc5udbXkwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2 on commond prommt\n",
        "pip install detectron2 -f \\\n",
        "https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html\n"
      ],
      "metadata": {
        "id": "zpH-BE8kYXqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then Verify installation\n",
        "import detectron2\n",
        "print(detectron2.__version__)\n"
      ],
      "metadata": {
        "id": "r9h9NMyDYc3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "0.6\n"
      ],
      "metadata": {
        "id": "f97yGuJ4Ygrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Annotate a dataset and convert annotations to COCO format for Detectron2."
      ],
      "metadata": {
        "id": "ANMF4xNrYkr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "mAeSIVD1Yq4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool Used: LabelImg\n",
        "Steps:\n",
        "\n",
        "1. Annotate images using LabelImg\n",
        "\n",
        "2. Export annotations as XML\n",
        "\n",
        "3. Convert XML to COCO JSON"
      ],
      "metadata": {
        "id": "PVWIc5WYYtaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Example structure of COCO format\n",
        "coco_format = {\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": []\n",
        "}\n",
        "\n",
        "with open(\"annotations.json\", \"w\") as f:\n",
        "    json.dump(coco_format, f)\n"
      ],
      "metadata": {
        "id": "aJhuLV6qY054"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "annotations.json created successfully\n"
      ],
      "metadata": {
        "id": "usXz_zqtY5vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a script to download pretrained weights and configure paths for training in Detectron2."
      ],
      "metadata": {
        "id": "dOfNGRfSY9Jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "pjVNL3OjZAfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzND0bSabhjo",
        "outputId": "7658c12e-d878-4529-b687-f170fc7bc51b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-566_ykr1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-566_ykr1\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit fd27788985af0f4ca800bca563acdb700bb890e2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.0.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.2.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (8.3.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (4.5.1)\n",
            "Collecting pytokens>=0.3.0 (from black->detectron2==0.6)\n",
            "  Downloading pytokens-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->detectron2==0.6) (4.15.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-1.0.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytokens-0.3.0-py3-none-any.whl (12 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp312-cp312-linux_x86_64.whl size=6706395 sha256=6e1565843ad4a1cc937eb5f306b135f279b8d435a2c01a1cf1c09bd76e6cd38c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0y1k8lzf/wheels/d3/6e/bd/1969578f1456a6be2d6f083da65c669f450b23b8f3d1ac14c1\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=9d994a9402f53b98e49ae0c679360fb5973d2913d5cc7313bed37e7059722f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built detectron2 fvcore\n",
            "Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed black-25.12.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-1.0.2 portalocker-3.2.0 pytokens-0.3.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\n",
        "    model_zoo.get_config_file(\n",
        "        \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
        "    )\n",
        ")\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "    \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
        ")\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"my_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_val\",)\n",
        "cfg.OUTPUT_DIR = \"./output\"\n",
        "print(\"Train Dataset:\", cfg.DATASETS.TRAIN)\n",
        "print(\"Test Dataset:\", cfg.DATASETS.TEST)\n",
        "print(\"Weights:\", cfg.MODEL.WEIGHTS)\n",
        "print(\"Output Dir:\", cfg.OUTPUT_DIR)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYIn9xicZC_0",
        "outputId": "1a2ba02e-5a54-4a01-cae5-dd78c94882ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: ('my_train',)\n",
            "Test Dataset: ('my_val',)\n",
            "Weights: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
            "Output Dir: ./output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Show the steps and code to run inference using a trained Detectron2 model on a new image."
      ],
      "metadata": {
        "id": "3CTnPT7VdEGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "AEFJBtNxdIuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgAm7NfjeqdU",
        "outputId": "0c72b160-1f84-4568-f6c3-085199a1fe5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations.json  IMG-20241221-WA0015.jpg  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultPredictor\n",
        "import cv2\n",
        "\n",
        "# CPU mode (safe)\n",
        "cfg.MODEL.DEVICE = \"cpu\"\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Correct image path\n",
        "img = cv2.imread(\"/content/IMG-20241221-WA0015.jpg\")\n",
        "\n",
        "if img is None:\n",
        "    raise ValueError(\"Image not found. Check filename or path!\")\n",
        "\n",
        "outputs = predictor(img)\n",
        "\n",
        "print(outputs[\"instances\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2gBcM4QdLRs",
        "outputId": "cf0abb93-9e0a-473f-a4dc-58e43697178d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "W0108 16:41:47.519000 4440 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instances(num_instances=51, image_height=4032, image_width=3024, fields=[pred_boxes: Boxes(tensor([[7.3336e+02, 2.0050e+03, 2.9397e+03, 3.9646e+03],\n",
            "        [5.2139e+02, 1.6519e+03, 7.7544e+02, 2.4667e+03],\n",
            "        [7.2237e+02, 1.5861e+03, 9.8262e+02, 2.3456e+03],\n",
            "        [1.1823e+03, 1.7295e+03, 1.2900e+03, 2.0704e+03],\n",
            "        [1.9812e+00, 1.9235e+03, 1.8776e+02, 2.3265e+03],\n",
            "        [1.6249e+03, 1.7862e+03, 1.6738e+03, 1.8734e+03],\n",
            "        [1.6991e+03, 1.7789e+03, 1.7706e+03, 1.9022e+03],\n",
            "        [1.1006e+03, 1.7537e+03, 1.1822e+03, 2.0415e+03],\n",
            "        [1.7123e+03, 1.8873e+03, 1.7817e+03, 2.0391e+03],\n",
            "        [2.0637e+02, 2.3141e+03, 2.6002e+02, 2.3665e+03],\n",
            "        [1.7074e+03, 1.8728e+03, 1.7761e+03, 1.9890e+03],\n",
            "        [8.3557e+02, 1.6985e+03, 9.7677e+02, 1.9136e+03],\n",
            "        [1.5449e+03, 1.6649e+03, 1.5783e+03, 1.7310e+03],\n",
            "        [1.6989e+03, 1.6698e+03, 1.7482e+03, 1.7204e+03],\n",
            "        [2.0505e+02, 2.3089e+03, 3.0717e+02, 2.3740e+03],\n",
            "        [1.6812e+03, 1.7733e+03, 1.7853e+03, 2.0229e+03],\n",
            "        [2.5424e+02, 2.3062e+03, 3.0522e+02, 2.3532e+03],\n",
            "        [1.6824e+03, 1.6721e+03, 1.7477e+03, 1.7831e+03],\n",
            "        [6.0119e+02, 1.9715e+03, 7.5228e+02, 2.1125e+03],\n",
            "        [1.7133e+03, 1.7810e+03, 1.7649e+03, 1.8403e+03],\n",
            "        [1.4761e+03, 1.6615e+03, 1.5151e+03, 1.7353e+03],\n",
            "        [1.6718e+03, 1.6832e+03, 1.7184e+03, 1.7650e+03],\n",
            "        [2.9421e+03, 1.6128e+03, 3.0198e+03, 2.5454e+03],\n",
            "        [1.1659e+03, 2.2540e+03, 1.2848e+03, 2.3506e+03],\n",
            "        [1.6990e+03, 1.8733e+03, 1.7740e+03, 2.0101e+03],\n",
            "        [1.6900e+03, 1.7812e+03, 1.7409e+03, 1.8986e+03],\n",
            "        [1.6632e+03, 1.6565e+03, 1.7666e+03, 1.9028e+03],\n",
            "        [1.2171e+03, 1.6389e+03, 1.2603e+03, 1.6971e+03],\n",
            "        [8.3506e+02, 1.7114e+03, 9.7880e+02, 2.1339e+03],\n",
            "        [8.1423e+01, 2.3330e+03, 2.0639e+02, 2.3787e+03],\n",
            "        [1.6908e+03, 2.7426e+03, 3.0240e+03, 4.0029e+03],\n",
            "        [1.5905e+02, 2.3381e+03, 2.1191e+02, 2.3716e+03],\n",
            "        [1.5502e+03, 1.6460e+03, 1.5942e+03, 1.7299e+03],\n",
            "        [8.0861e+01, 2.3316e+03, 2.0599e+02, 2.3788e+03],\n",
            "        [1.4608e+03, 1.6536e+03, 1.5050e+03, 1.7316e+03],\n",
            "        [1.6253e+03, 1.8041e+03, 1.6713e+03, 1.8754e+03],\n",
            "        [5.7795e+02, 1.7894e+03, 7.5973e+02, 2.1158e+03],\n",
            "        [2.4566e+02, 2.3138e+03, 3.0124e+02, 2.3718e+03],\n",
            "        [7.1142e-01, 2.2778e+03, 1.8574e+02, 2.3759e+03],\n",
            "        [2.3940e+02, 2.3155e+03, 3.4007e+02, 2.3810e+03],\n",
            "        [1.6935e+03, 1.8159e+03, 1.7673e+03, 1.9253e+03],\n",
            "        [1.0268e+03, 2.3260e+03, 1.0820e+03, 2.4004e+03],\n",
            "        [2.0102e+03, 2.7416e+03, 3.0070e+03, 3.9717e+03],\n",
            "        [1.6788e+03, 1.8073e+03, 1.7866e+03, 2.0450e+03],\n",
            "        [1.3886e+01, 2.6569e+03, 3.0021e+03, 3.9944e+03],\n",
            "        [1.5814e+03, 1.6709e+03, 1.6052e+03, 1.7375e+03],\n",
            "        [1.8200e+02, 2.5470e+03, 2.8334e+03, 3.9720e+03],\n",
            "        [7.7963e+02, 1.6927e+03, 9.4584e+02, 2.0469e+03],\n",
            "        [1.8328e+01, 2.3268e+03, 4.0357e+02, 2.4337e+03],\n",
            "        [1.6886e+03, 1.8245e+03, 1.7875e+03, 2.0379e+03],\n",
            "        [1.6878e+03, 1.7939e+03, 1.7473e+03, 1.8989e+03]])), scores: tensor([0.9972, 0.9955, 0.9930, 0.9796, 0.9747, 0.8995, 0.8098, 0.5060, 0.4829,\n",
            "        0.3784, 0.3605, 0.3598, 0.3090, 0.2860, 0.2690, 0.2618, 0.2599, 0.2503,\n",
            "        0.2439, 0.2195, 0.1724, 0.1710, 0.1663, 0.1574, 0.1554, 0.1508, 0.1455,\n",
            "        0.1445, 0.1368, 0.1314, 0.1206, 0.1156, 0.1035, 0.0970, 0.0927, 0.0889,\n",
            "        0.0878, 0.0869, 0.0847, 0.0793, 0.0713, 0.0685, 0.0681, 0.0669, 0.0620,\n",
            "        0.0588, 0.0562, 0.0550, 0.0524, 0.0516, 0.0506]), pred_classes: tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  3, 47,  0, 26,  0,  0, 47,  0, 47,  0,\n",
            "        26,  0,  0,  0,  0, 67,  1,  0,  0,  0, 26, 47, 59, 47,  0, 46,  0,  3,\n",
            "        26, 47, 46, 47,  1, 67, 57,  1, 59,  0, 13, 26, 45,  3,  1])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Wildlife monitoring system using Detectron2 (End-to-End Pipeline)"
      ],
      "metadata": {
        "id": "X-ppaRhefI3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "0st8XlYmfWeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline:\n",
        "\n",
        "1. Data Collection:\n",
        "Capture images/videos using camera traps\n",
        "\n",
        "2. Data Annotation:\n",
        "Label animals using bounding boxes and masks\n",
        "\n",
        "3. Data Preprocessing:\n",
        "Convert annotations to COCO format\n",
        "\n",
        "4. Model Training:\n",
        "Train Mask R-CNN using Detectron2\n",
        "\n",
        "5. Handling Challenges:\n",
        "\n",
        "* Occlusion → Use instance segmentation\n",
        "\n",
        "* Night detection → Infrared cameras + data augmentation\n",
        "\n",
        "6. Inference & Tracking:\n",
        "Run inference on live video feeds\n",
        "\n",
        "7. Deployment:\n",
        "Deploy using REST API or edge devices"
      ],
      "metadata": {
        "id": "L3KQ99LWfZug"
      }
    }
  ]
}